{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "igMyGnjE9hEp"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2HDvhIu9hEr"
      },
      "source": [
        "# Specify each path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9NvZP2Zn9hEy"
      },
      "outputs": [],
      "source": [
        "dataset = '/home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint.csv'\n",
        "model_save_path = '/home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5'\n",
        "tflite_save_path = '/home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.tflite'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5oMH7x19hEz"
      },
      "source": [
        "# Set number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "du4kodXL9hEz"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjnL0uso9hEz"
      },
      "source": [
        "# Dataset reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QT5ZqtEz9hE0"
      },
      "outputs": [],
      "source": [
        "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QmoKFsp49hE0"
      },
      "outputs": [],
      "source": [
        "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xQU7JTZ_9hE0"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxK_lETT9hE0"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vHBmUf1t9hE1"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input((21 * 2, )),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypqky9tc9hE1",
        "outputId": "5db082bb-30e3-4110-bf63-a1ee777ecd46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout_2 (Dropout)         (None, 42)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 20)                860       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                210       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 6)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,136\n",
            "Trainable params: 1,136\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "MbMjOflQ9hE1"
      },
      "outputs": [],
      "source": [
        "# Model checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    model_save_path, verbose=1, save_weights_only=False)\n",
        "# Callback for early stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "c3Dac0M_9hE2"
      },
      "outputs": [],
      "source": [
        "# Model compilation\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XI0j1Iu9hE2"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WirBl-JE9hE3",
        "outputId": "71b30ca2-8294-4d9d-8aa2-800d90d399de",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 1.8059 - accuracy: 0.2252\n",
            "Epoch 1: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 1.7791 - accuracy: 0.2399 - val_loss: 1.6251 - val_accuracy: 0.3581\n",
            "Epoch 2/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 1.5990 - accuracy: 0.3284\n",
            "Epoch 2: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.5884 - accuracy: 0.3320 - val_loss: 1.4731 - val_accuracy: 0.3830\n",
            "Epoch 3/1000\n",
            "26/38 [===================>..........] - ETA: 0s - loss: 1.4777 - accuracy: 0.3705\n",
            "Epoch 3: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 1.4613 - accuracy: 0.3811 - val_loss: 1.3373 - val_accuracy: 0.4454\n",
            "Epoch 4/1000\n",
            "18/38 [=============>................] - ETA: 0s - loss: 1.3797 - accuracy: 0.4184\n",
            "Epoch 4: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 1.3426 - accuracy: 0.4294 - val_loss: 1.1713 - val_accuracy: 0.5097\n",
            "Epoch 5/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 1.2390 - accuracy: 0.4742\n",
            "Epoch 5: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.2353 - accuracy: 0.4726 - val_loss: 1.0226 - val_accuracy: 0.6313\n",
            "Epoch 6/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 1.1556 - accuracy: 0.5040\n",
            "Epoch 6: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 1.1519 - accuracy: 0.5020 - val_loss: 0.9243 - val_accuracy: 0.6538\n",
            "Epoch 7/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 1.0776 - accuracy: 0.5228\n",
            "Epoch 7: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 1.0749 - accuracy: 0.5247 - val_loss: 0.8481 - val_accuracy: 0.6581\n",
            "Epoch 8/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 1.0268 - accuracy: 0.5270\n",
            "Epoch 8: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 1.0130 - accuracy: 0.5369 - val_loss: 0.7946 - val_accuracy: 0.6644\n",
            "Epoch 9/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.9935 - accuracy: 0.5504\n",
            "Epoch 9: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.9878 - accuracy: 0.5571 - val_loss: 0.7574 - val_accuracy: 0.6806\n",
            "Epoch 10/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.9370 - accuracy: 0.5938\n",
            "Epoch 10: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.9379 - accuracy: 0.5921 - val_loss: 0.7191 - val_accuracy: 0.7043\n",
            "Epoch 11/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.9125 - accuracy: 0.6091\n",
            "Epoch 11: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.9125 - accuracy: 0.6091 - val_loss: 0.6873 - val_accuracy: 0.7355\n",
            "Epoch 12/1000\n",
            "24/38 [=================>............] - ETA: 0s - loss: 0.8986 - accuracy: 0.6149\n",
            "Epoch 12: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.8903 - accuracy: 0.6195 - val_loss: 0.6653 - val_accuracy: 0.7723\n",
            "Epoch 13/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.8912 - accuracy: 0.6243\n",
            "Epoch 13: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.8790 - accuracy: 0.6364 - val_loss: 0.6427 - val_accuracy: 0.8104\n",
            "Epoch 14/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.8440 - accuracy: 0.6513\n",
            "Epoch 14: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.8441 - accuracy: 0.6497 - val_loss: 0.6133 - val_accuracy: 0.8210\n",
            "Epoch 15/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.8304 - accuracy: 0.6522\n",
            "Epoch 15: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.8315 - accuracy: 0.6522 - val_loss: 0.5941 - val_accuracy: 0.8284\n",
            "Epoch 16/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.8103 - accuracy: 0.6714\n",
            "Epoch 16: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.8125 - accuracy: 0.6699 - val_loss: 0.5777 - val_accuracy: 0.8334\n",
            "Epoch 17/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.7970 - accuracy: 0.6839\n",
            "Epoch 17: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.7933 - accuracy: 0.6817 - val_loss: 0.5578 - val_accuracy: 0.8309\n",
            "Epoch 18/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.7714 - accuracy: 0.6844\n",
            "Epoch 18: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.7714 - accuracy: 0.6844 - val_loss: 0.5341 - val_accuracy: 0.8422\n",
            "Epoch 19/1000\n",
            "26/38 [===================>..........] - ETA: 0s - loss: 0.7581 - accuracy: 0.6788\n",
            "Epoch 19: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.7587 - accuracy: 0.6828 - val_loss: 0.5165 - val_accuracy: 0.8478\n",
            "Epoch 20/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.7528 - accuracy: 0.6890\n",
            "Epoch 20: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.7485 - accuracy: 0.6950 - val_loss: 0.4989 - val_accuracy: 0.8509\n",
            "Epoch 21/1000\n",
            "29/38 [=====================>........] - ETA: 0s - loss: 0.7281 - accuracy: 0.7101\n",
            "Epoch 21: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.7269 - accuracy: 0.7131 - val_loss: 0.4789 - val_accuracy: 0.8628\n",
            "Epoch 22/1000\n",
            "11/38 [=======>......................] - ETA: 0s - loss: 0.6731 - accuracy: 0.7450\n",
            "Epoch 22: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6985 - accuracy: 0.7289 - val_loss: 0.4556 - val_accuracy: 0.8671\n",
            "Epoch 23/1000\n",
            "19/38 [==============>...............] - ETA: 0s - loss: 0.6889 - accuracy: 0.7319\n",
            "Epoch 23: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6947 - accuracy: 0.7275 - val_loss: 0.4393 - val_accuracy: 0.8746\n",
            "Epoch 24/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.6809 - accuracy: 0.7339\n",
            "Epoch 24: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6772 - accuracy: 0.7341 - val_loss: 0.4247 - val_accuracy: 0.8759\n",
            "Epoch 25/1000\n",
            "26/38 [===================>..........] - ETA: 0s - loss: 0.6599 - accuracy: 0.7422\n",
            "Epoch 25: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.6516 - accuracy: 0.7447 - val_loss: 0.4001 - val_accuracy: 0.8846\n",
            "Epoch 26/1000\n",
            "26/38 [===================>..........] - ETA: 0s - loss: 0.6633 - accuracy: 0.7329\n",
            "Epoch 26: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6646 - accuracy: 0.7343 - val_loss: 0.3933 - val_accuracy: 0.8865\n",
            "Epoch 27/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.6262 - accuracy: 0.7571\n",
            "Epoch 27: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6365 - accuracy: 0.7560 - val_loss: 0.3759 - val_accuracy: 0.8964\n",
            "Epoch 28/1000\n",
            "27/38 [====================>.........] - ETA: 0s - loss: 0.6291 - accuracy: 0.7581\n",
            "Epoch 28: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6273 - accuracy: 0.7574 - val_loss: 0.3596 - val_accuracy: 0.8902\n",
            "Epoch 29/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.6232 - accuracy: 0.7538\n",
            "Epoch 29: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6245 - accuracy: 0.7522 - val_loss: 0.3485 - val_accuracy: 0.9239\n",
            "Epoch 30/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.6080 - accuracy: 0.7612\n",
            "Epoch 30: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.6106 - accuracy: 0.7608 - val_loss: 0.3338 - val_accuracy: 0.9083\n",
            "Epoch 31/1000\n",
            "27/38 [====================>.........] - ETA: 0s - loss: 0.5848 - accuracy: 0.7758\n",
            "Epoch 31: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.5851 - accuracy: 0.7772 - val_loss: 0.3201 - val_accuracy: 0.9308\n",
            "Epoch 32/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.6171 - accuracy: 0.7634\n",
            "Epoch 32: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.6098 - accuracy: 0.7631 - val_loss: 0.3138 - val_accuracy: 0.9370\n",
            "Epoch 33/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.5721 - accuracy: 0.7752\n",
            "Epoch 33: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.5788 - accuracy: 0.7743 - val_loss: 0.3108 - val_accuracy: 0.9314\n",
            "Epoch 34/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.5812 - accuracy: 0.7790\n",
            "Epoch 34: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.5717 - accuracy: 0.7876 - val_loss: 0.2888 - val_accuracy: 0.9370\n",
            "Epoch 35/1000\n",
            "25/38 [==================>...........] - ETA: 0s - loss: 0.5499 - accuracy: 0.7997\n",
            "Epoch 35: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7951 - val_loss: 0.2810 - val_accuracy: 0.9389\n",
            "Epoch 36/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5511 - accuracy: 0.7851\n",
            "Epoch 36: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.5511 - accuracy: 0.7851 - val_loss: 0.2756 - val_accuracy: 0.9333\n",
            "Epoch 37/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.5606 - accuracy: 0.7789\n",
            "Epoch 37: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.5582 - accuracy: 0.7814 - val_loss: 0.2744 - val_accuracy: 0.9357\n",
            "Epoch 38/1000\n",
            "15/38 [==========>...................] - ETA: 0s - loss: 0.5884 - accuracy: 0.7766\n",
            "Epoch 38: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.7832 - val_loss: 0.2708 - val_accuracy: 0.9357\n",
            "Epoch 39/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.5610 - accuracy: 0.7895\n",
            "Epoch 39: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.5617 - accuracy: 0.7876 - val_loss: 0.2643 - val_accuracy: 0.9370\n",
            "Epoch 40/1000\n",
            "24/38 [=================>............] - ETA: 0s - loss: 0.5406 - accuracy: 0.7943\n",
            "Epoch 40: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7953 - val_loss: 0.2496 - val_accuracy: 0.9364\n",
            "Epoch 41/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5237 - accuracy: 0.8067\n",
            "Epoch 41: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.8067 - val_loss: 0.2481 - val_accuracy: 0.9389\n",
            "Epoch 42/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.5366 - accuracy: 0.8007\n",
            "Epoch 42: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.5347 - accuracy: 0.8011 - val_loss: 0.2402 - val_accuracy: 0.9432\n",
            "Epoch 43/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.5280 - accuracy: 0.8004\n",
            "Epoch 43: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.5229 - accuracy: 0.8020 - val_loss: 0.2313 - val_accuracy: 0.9451\n",
            "Epoch 44/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.5354 - accuracy: 0.7953\n",
            "Epoch 44: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.5360 - accuracy: 0.7953 - val_loss: 0.2281 - val_accuracy: 0.9451\n",
            "Epoch 45/1000\n",
            "24/38 [=================>............] - ETA: 0s - loss: 0.5123 - accuracy: 0.8148\n",
            "Epoch 45: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.8119 - val_loss: 0.2271 - val_accuracy: 0.9445\n",
            "Epoch 46/1000\n",
            "25/38 [==================>...........] - ETA: 0s - loss: 0.5222 - accuracy: 0.8134\n",
            "Epoch 46: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.8126 - val_loss: 0.2245 - val_accuracy: 0.9451\n",
            "Epoch 47/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5267 - accuracy: 0.8005\n",
            "Epoch 47: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.5251 - accuracy: 0.8009 - val_loss: 0.2177 - val_accuracy: 0.9557\n",
            "Epoch 48/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.5176 - accuracy: 0.8054\n",
            "Epoch 48: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.5056 - accuracy: 0.8063 - val_loss: 0.2252 - val_accuracy: 0.9389\n",
            "Epoch 49/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.5029 - accuracy: 0.8022\n",
            "Epoch 49: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5120 - accuracy: 0.8017 - val_loss: 0.2166 - val_accuracy: 0.9513\n",
            "Epoch 50/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.4908 - accuracy: 0.8206\n",
            "Epoch 50: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.8209 - val_loss: 0.2178 - val_accuracy: 0.9426\n",
            "Epoch 51/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.4833 - accuracy: 0.8259\n",
            "Epoch 51: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.8207 - val_loss: 0.2130 - val_accuracy: 0.9488\n",
            "Epoch 52/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.4933 - accuracy: 0.8129\n",
            "Epoch 52: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.8182 - val_loss: 0.2095 - val_accuracy: 0.9488\n",
            "Epoch 53/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.4965 - accuracy: 0.8095\n",
            "Epoch 53: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4947 - accuracy: 0.8115 - val_loss: 0.2060 - val_accuracy: 0.9470\n",
            "Epoch 54/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.4989 - accuracy: 0.8130\n",
            "Epoch 54: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4908 - accuracy: 0.8167 - val_loss: 0.2067 - val_accuracy: 0.9420\n",
            "Epoch 55/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.4860 - accuracy: 0.8159\n",
            "Epoch 55: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4880 - accuracy: 0.8136 - val_loss: 0.2049 - val_accuracy: 0.9538\n",
            "Epoch 56/1000\n",
            "23/38 [=================>............] - ETA: 0s - loss: 0.5031 - accuracy: 0.8207\n",
            "Epoch 56: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4966 - accuracy: 0.8190 - val_loss: 0.2036 - val_accuracy: 0.9482\n",
            "Epoch 57/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.4849 - accuracy: 0.8234\n",
            "Epoch 57: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4887 - accuracy: 0.8223 - val_loss: 0.1986 - val_accuracy: 0.9563\n",
            "Epoch 58/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.5040 - accuracy: 0.8171\n",
            "Epoch 58: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.5010 - accuracy: 0.8161 - val_loss: 0.2043 - val_accuracy: 0.9538\n",
            "Epoch 59/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4932 - accuracy: 0.8182\n",
            "Epoch 59: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4932 - accuracy: 0.8182 - val_loss: 0.1995 - val_accuracy: 0.9476\n",
            "Epoch 60/1000\n",
            "25/38 [==================>...........] - ETA: 0s - loss: 0.5008 - accuracy: 0.8109\n",
            "Epoch 60: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.8103 - val_loss: 0.2018 - val_accuracy: 0.9488\n",
            "Epoch 61/1000\n",
            "23/38 [=================>............] - ETA: 0s - loss: 0.4781 - accuracy: 0.8207\n",
            "Epoch 61: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.8236 - val_loss: 0.1983 - val_accuracy: 0.9538\n",
            "Epoch 62/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4731 - accuracy: 0.8282\n",
            "Epoch 62: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4731 - accuracy: 0.8282 - val_loss: 0.1947 - val_accuracy: 0.9507\n",
            "Epoch 63/1000\n",
            "24/38 [=================>............] - ETA: 0s - loss: 0.4951 - accuracy: 0.8226\n",
            "Epoch 63: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.8238 - val_loss: 0.1922 - val_accuracy: 0.9526\n",
            "Epoch 64/1000\n",
            "19/38 [==============>...............] - ETA: 0s - loss: 0.4643 - accuracy: 0.8207\n",
            "Epoch 64: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.8209 - val_loss: 0.1925 - val_accuracy: 0.9557\n",
            "Epoch 65/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.4770 - accuracy: 0.8252\n",
            "Epoch 65: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.8257 - val_loss: 0.1915 - val_accuracy: 0.9532\n",
            "Epoch 66/1000\n",
            "25/38 [==================>...........] - ETA: 0s - loss: 0.4551 - accuracy: 0.8369\n",
            "Epoch 66: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.8265 - val_loss: 0.1892 - val_accuracy: 0.9507\n",
            "Epoch 67/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.4778 - accuracy: 0.8218\n",
            "Epoch 67: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.8267 - val_loss: 0.1903 - val_accuracy: 0.9495\n",
            "Epoch 68/1000\n",
            "18/38 [=============>................] - ETA: 0s - loss: 0.4714 - accuracy: 0.8351\n",
            "Epoch 68: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4746 - accuracy: 0.8319 - val_loss: 0.1845 - val_accuracy: 0.9607\n",
            "Epoch 69/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.4511 - accuracy: 0.8313\n",
            "Epoch 69: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.8298 - val_loss: 0.1897 - val_accuracy: 0.9557\n",
            "Epoch 70/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4676 - accuracy: 0.8311\n",
            "Epoch 70: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.8311 - val_loss: 0.1894 - val_accuracy: 0.9513\n",
            "Epoch 71/1000\n",
            "17/38 [============>.................] - ETA: 0s - loss: 0.4363 - accuracy: 0.8447\n",
            "Epoch 71: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.8398 - val_loss: 0.1804 - val_accuracy: 0.9570\n",
            "Epoch 72/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.4799 - accuracy: 0.8267\n",
            "Epoch 72: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4742 - accuracy: 0.8269 - val_loss: 0.1779 - val_accuracy: 0.9601\n",
            "Epoch 73/1000\n",
            "17/38 [============>.................] - ETA: 0s - loss: 0.4658 - accuracy: 0.8203\n",
            "Epoch 73: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.8305 - val_loss: 0.1792 - val_accuracy: 0.9563\n",
            "Epoch 74/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.4582 - accuracy: 0.8383\n",
            "Epoch 74: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.8386 - val_loss: 0.1802 - val_accuracy: 0.9582\n",
            "Epoch 75/1000\n",
            "23/38 [=================>............] - ETA: 0s - loss: 0.4818 - accuracy: 0.8200\n",
            "Epoch 75: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.8234 - val_loss: 0.1786 - val_accuracy: 0.9595\n",
            "Epoch 76/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.4680 - accuracy: 0.8264\n",
            "Epoch 76: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.8286 - val_loss: 0.1787 - val_accuracy: 0.9557\n",
            "Epoch 77/1000\n",
            "27/38 [====================>.........] - ETA: 0s - loss: 0.4735 - accuracy: 0.8284\n",
            "Epoch 77: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4693 - accuracy: 0.8298 - val_loss: 0.1776 - val_accuracy: 0.9595\n",
            "Epoch 78/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.4539 - accuracy: 0.8324\n",
            "Epoch 78: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4460 - accuracy: 0.8363 - val_loss: 0.1806 - val_accuracy: 0.9557\n",
            "Epoch 79/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.4434 - accuracy: 0.8385\n",
            "Epoch 79: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.8361 - val_loss: 0.1743 - val_accuracy: 0.9545\n",
            "Epoch 80/1000\n",
            "23/38 [=================>............] - ETA: 0s - loss: 0.4541 - accuracy: 0.8373\n",
            "Epoch 80: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4578 - accuracy: 0.8359 - val_loss: 0.1718 - val_accuracy: 0.9582\n",
            "Epoch 81/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4568 - accuracy: 0.8319\n",
            "Epoch 81: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.8319 - val_loss: 0.1733 - val_accuracy: 0.9632\n",
            "Epoch 82/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.4425 - accuracy: 0.8366\n",
            "Epoch 82: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.8344 - val_loss: 0.1725 - val_accuracy: 0.9607\n",
            "Epoch 83/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.4295 - accuracy: 0.8438\n",
            "Epoch 83: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.8456 - val_loss: 0.1753 - val_accuracy: 0.9570\n",
            "Epoch 84/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.4467 - accuracy: 0.8289\n",
            "Epoch 84: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.8371 - val_loss: 0.1698 - val_accuracy: 0.9551\n",
            "Epoch 85/1000\n",
            "27/38 [====================>.........] - ETA: 0s - loss: 0.4567 - accuracy: 0.8333\n",
            "Epoch 85: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.8342 - val_loss: 0.1753 - val_accuracy: 0.9582\n",
            "Epoch 86/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.4413 - accuracy: 0.8427\n",
            "Epoch 86: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4449 - accuracy: 0.8421 - val_loss: 0.1689 - val_accuracy: 0.9613\n",
            "Epoch 87/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.4413 - accuracy: 0.8348\n",
            "Epoch 87: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4439 - accuracy: 0.8330 - val_loss: 0.1740 - val_accuracy: 0.9588\n",
            "Epoch 88/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.4418 - accuracy: 0.8390\n",
            "Epoch 88: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.8327 - val_loss: 0.1680 - val_accuracy: 0.9644\n",
            "Epoch 89/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.4436 - accuracy: 0.8366\n",
            "Epoch 89: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4477 - accuracy: 0.8359 - val_loss: 0.1675 - val_accuracy: 0.9638\n",
            "Epoch 90/1000\n",
            "25/38 [==================>...........] - ETA: 0s - loss: 0.4521 - accuracy: 0.8316\n",
            "Epoch 90: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4554 - accuracy: 0.8327 - val_loss: 0.1758 - val_accuracy: 0.9613\n",
            "Epoch 91/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.4390 - accuracy: 0.8423\n",
            "Epoch 91: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4390 - accuracy: 0.8421 - val_loss: 0.1691 - val_accuracy: 0.9601\n",
            "Epoch 92/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.4349 - accuracy: 0.8406\n",
            "Epoch 92: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.8419 - val_loss: 0.1703 - val_accuracy: 0.9582\n",
            "Epoch 93/1000\n",
            "24/38 [=================>............] - ETA: 0s - loss: 0.4456 - accuracy: 0.8359\n",
            "Epoch 93: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8415 - val_loss: 0.1646 - val_accuracy: 0.9638\n",
            "Epoch 94/1000\n",
            "19/38 [==============>...............] - ETA: 0s - loss: 0.4503 - accuracy: 0.8351\n",
            "Epoch 94: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.8427 - val_loss: 0.1674 - val_accuracy: 0.9582\n",
            "Epoch 95/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.4169 - accuracy: 0.8447\n",
            "Epoch 95: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8448 - val_loss: 0.1558 - val_accuracy: 0.9657\n",
            "Epoch 96/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4432 - accuracy: 0.8391\n",
            "Epoch 96: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.8388 - val_loss: 0.1657 - val_accuracy: 0.9613\n",
            "Epoch 97/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.4296 - accuracy: 0.8454\n",
            "Epoch 97: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.8415 - val_loss: 0.1650 - val_accuracy: 0.9638\n",
            "Epoch 98/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.4316 - accuracy: 0.8471\n",
            "Epoch 98: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4383 - accuracy: 0.8434 - val_loss: 0.1665 - val_accuracy: 0.9601\n",
            "Epoch 99/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.4150 - accuracy: 0.8443\n",
            "Epoch 99: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.8406 - val_loss: 0.1654 - val_accuracy: 0.9619\n",
            "Epoch 100/1000\n",
            "23/38 [=================>............] - ETA: 0s - loss: 0.4284 - accuracy: 0.8366\n",
            "Epoch 100: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8396 - val_loss: 0.1644 - val_accuracy: 0.9669\n",
            "Epoch 101/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.4270 - accuracy: 0.8412\n",
            "Epoch 101: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4249 - accuracy: 0.8454 - val_loss: 0.1640 - val_accuracy: 0.9588\n",
            "Epoch 102/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.4127 - accuracy: 0.8479\n",
            "Epoch 102: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.8454 - val_loss: 0.1598 - val_accuracy: 0.9613\n",
            "Epoch 103/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.4253 - accuracy: 0.8478\n",
            "Epoch 103: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.8473 - val_loss: 0.1601 - val_accuracy: 0.9607\n",
            "Epoch 104/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.4335 - accuracy: 0.8384\n",
            "Epoch 104: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4294 - accuracy: 0.8406 - val_loss: 0.1599 - val_accuracy: 0.9676\n",
            "Epoch 105/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.4366 - accuracy: 0.8380\n",
            "Epoch 105: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4345 - accuracy: 0.8392 - val_loss: 0.1557 - val_accuracy: 0.9651\n",
            "Epoch 106/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.4241 - accuracy: 0.8482\n",
            "Epoch 106: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4322 - accuracy: 0.8446 - val_loss: 0.1620 - val_accuracy: 0.9651\n",
            "Epoch 107/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.4343 - accuracy: 0.8393\n",
            "Epoch 107: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.8386 - val_loss: 0.1622 - val_accuracy: 0.9657\n",
            "Epoch 108/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.4196 - accuracy: 0.8457\n",
            "Epoch 108: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8434 - val_loss: 0.1615 - val_accuracy: 0.9632\n",
            "Epoch 109/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.4265 - accuracy: 0.8435\n",
            "Epoch 109: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.4243 - accuracy: 0.8473 - val_loss: 0.1586 - val_accuracy: 0.9638\n",
            "Epoch 110/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.4306 - accuracy: 0.8388\n",
            "Epoch 110: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.8386 - val_loss: 0.1621 - val_accuracy: 0.9638\n",
            "Epoch 111/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.4423 - accuracy: 0.8432\n",
            "Epoch 111: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.8436 - val_loss: 0.1635 - val_accuracy: 0.9644\n",
            "Epoch 112/1000\n",
            "29/38 [=====================>........] - ETA: 0s - loss: 0.4274 - accuracy: 0.8416\n",
            "Epoch 112: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.8415 - val_loss: 0.1595 - val_accuracy: 0.9651\n",
            "Epoch 113/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4204 - accuracy: 0.8486\n",
            "Epoch 113: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.8486 - val_loss: 0.1557 - val_accuracy: 0.9657\n",
            "Epoch 114/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.4448 - accuracy: 0.8404\n",
            "Epoch 114: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.8384 - val_loss: 0.1580 - val_accuracy: 0.9651\n",
            "Epoch 115/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.4295 - accuracy: 0.8430\n",
            "Epoch 115: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.8427 - val_loss: 0.1531 - val_accuracy: 0.9657\n",
            "Epoch 116/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4330 - accuracy: 0.8376\n",
            "Epoch 116: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.8371 - val_loss: 0.1570 - val_accuracy: 0.9682\n",
            "Epoch 117/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.4087 - accuracy: 0.8471\n",
            "Epoch 117: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8463 - val_loss: 0.1546 - val_accuracy: 0.9638\n",
            "Epoch 118/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.4189 - accuracy: 0.8363\n",
            "Epoch 118: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8448 - val_loss: 0.1544 - val_accuracy: 0.9644\n",
            "Epoch 119/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4248 - accuracy: 0.8423\n",
            "Epoch 119: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.8425 - val_loss: 0.1524 - val_accuracy: 0.9676\n",
            "Epoch 120/1000\n",
            "29/38 [=====================>........] - ETA: 0s - loss: 0.4183 - accuracy: 0.8497\n",
            "Epoch 120: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.8500 - val_loss: 0.1533 - val_accuracy: 0.9676\n",
            "Epoch 121/1000\n",
            "18/38 [=============>................] - ETA: 0s - loss: 0.4467 - accuracy: 0.8398\n",
            "Epoch 121: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8429 - val_loss: 0.1555 - val_accuracy: 0.9694\n",
            "Epoch 122/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4233 - accuracy: 0.8516\n",
            "Epoch 122: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8515 - val_loss: 0.1541 - val_accuracy: 0.9651\n",
            "Epoch 123/1000\n",
            "27/38 [====================>.........] - ETA: 0s - loss: 0.4188 - accuracy: 0.8490\n",
            "Epoch 123: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.8498 - val_loss: 0.1525 - val_accuracy: 0.9688\n",
            "Epoch 124/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.4099 - accuracy: 0.8548\n",
            "Epoch 124: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8556 - val_loss: 0.1556 - val_accuracy: 0.9669\n",
            "Epoch 125/1000\n",
            "25/38 [==================>...........] - ETA: 0s - loss: 0.3922 - accuracy: 0.8547\n",
            "Epoch 125: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8506 - val_loss: 0.1450 - val_accuracy: 0.9688\n",
            "Epoch 126/1000\n",
            "29/38 [=====================>........] - ETA: 0s - loss: 0.4098 - accuracy: 0.8451\n",
            "Epoch 126: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.8446 - val_loss: 0.1471 - val_accuracy: 0.9663\n",
            "Epoch 127/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.4207 - accuracy: 0.8493\n",
            "Epoch 127: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.8504 - val_loss: 0.1519 - val_accuracy: 0.9694\n",
            "Epoch 128/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4152 - accuracy: 0.8478\n",
            "Epoch 128: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8488 - val_loss: 0.1495 - val_accuracy: 0.9713\n",
            "Epoch 129/1000\n",
            "24/38 [=================>............] - ETA: 0s - loss: 0.4131 - accuracy: 0.8555\n",
            "Epoch 129: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.8552 - val_loss: 0.1459 - val_accuracy: 0.9657\n",
            "Epoch 130/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4241 - accuracy: 0.8476\n",
            "Epoch 130: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4228 - accuracy: 0.8477 - val_loss: 0.1540 - val_accuracy: 0.9682\n",
            "Epoch 131/1000\n",
            "26/38 [===================>..........] - ETA: 0s - loss: 0.4089 - accuracy: 0.8516\n",
            "Epoch 131: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4062 - accuracy: 0.8521 - val_loss: 0.1495 - val_accuracy: 0.9669\n",
            "Epoch 132/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4111 - accuracy: 0.8502\n",
            "Epoch 132: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8502 - val_loss: 0.1500 - val_accuracy: 0.9682\n",
            "Epoch 133/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.4123 - accuracy: 0.8495\n",
            "Epoch 133: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4077 - accuracy: 0.8511 - val_loss: 0.1503 - val_accuracy: 0.9657\n",
            "Epoch 134/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.4265 - accuracy: 0.8477\n",
            "Epoch 134: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.8475 - val_loss: 0.1539 - val_accuracy: 0.9669\n",
            "Epoch 135/1000\n",
            "26/38 [===================>..........] - ETA: 0s - loss: 0.4134 - accuracy: 0.8492\n",
            "Epoch 135: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8467 - val_loss: 0.1509 - val_accuracy: 0.9657\n",
            "Epoch 136/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.4033 - accuracy: 0.8501\n",
            "Epoch 136: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8500 - val_loss: 0.1511 - val_accuracy: 0.9651\n",
            "Epoch 137/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.4177 - accuracy: 0.8423\n",
            "Epoch 137: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4200 - accuracy: 0.8427 - val_loss: 0.1449 - val_accuracy: 0.9694\n",
            "Epoch 138/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.4209 - accuracy: 0.8480\n",
            "Epoch 138: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4204 - accuracy: 0.8488 - val_loss: 0.1536 - val_accuracy: 0.9669\n",
            "Epoch 139/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.4009 - accuracy: 0.8576\n",
            "Epoch 139: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4113 - accuracy: 0.8544 - val_loss: 0.1510 - val_accuracy: 0.9657\n",
            "Epoch 140/1000\n",
            "25/38 [==================>...........] - ETA: 0s - loss: 0.4050 - accuracy: 0.8559\n",
            "Epoch 140: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8494 - val_loss: 0.1499 - val_accuracy: 0.9676\n",
            "Epoch 141/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4126 - accuracy: 0.8467\n",
            "Epoch 141: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8465 - val_loss: 0.1490 - val_accuracy: 0.9663\n",
            "Epoch 142/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.3906 - accuracy: 0.8574\n",
            "Epoch 142: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.3879 - accuracy: 0.8587 - val_loss: 0.1449 - val_accuracy: 0.9669\n",
            "Epoch 143/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3951 - accuracy: 0.8550\n",
            "Epoch 143: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.3902 - accuracy: 0.8552 - val_loss: 0.1434 - val_accuracy: 0.9707\n",
            "Epoch 144/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.4020 - accuracy: 0.8521\n",
            "Epoch 144: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8511 - val_loss: 0.1453 - val_accuracy: 0.9682\n",
            "Epoch 145/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.3982 - accuracy: 0.8574\n",
            "Epoch 145: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8535 - val_loss: 0.1471 - val_accuracy: 0.9682\n",
            "Epoch 146/1000\n",
            "24/38 [=================>............] - ETA: 0s - loss: 0.4056 - accuracy: 0.8486\n",
            "Epoch 146: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8511 - val_loss: 0.1486 - val_accuracy: 0.9713\n",
            "Epoch 147/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8619\n",
            "Epoch 147: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.3878 - accuracy: 0.8623 - val_loss: 0.1459 - val_accuracy: 0.9701\n",
            "Epoch 148/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.3976 - accuracy: 0.8563\n",
            "Epoch 148: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3980 - accuracy: 0.8565 - val_loss: 0.1481 - val_accuracy: 0.9682\n",
            "Epoch 149/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3963 - accuracy: 0.8581\n",
            "Epoch 149: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.3963 - accuracy: 0.8581 - val_loss: 0.1470 - val_accuracy: 0.9682\n",
            "Epoch 150/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.3999 - accuracy: 0.8536\n",
            "Epoch 150: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8577 - val_loss: 0.1396 - val_accuracy: 0.9707\n",
            "Epoch 151/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4085 - accuracy: 0.8486\n",
            "Epoch 151: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4086 - accuracy: 0.8481 - val_loss: 0.1411 - val_accuracy: 0.9713\n",
            "Epoch 152/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.3936 - accuracy: 0.8590\n",
            "Epoch 152: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8533 - val_loss: 0.1382 - val_accuracy: 0.9726\n",
            "Epoch 153/1000\n",
            "24/38 [=================>............] - ETA: 0s - loss: 0.4163 - accuracy: 0.8529\n",
            "Epoch 153: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.8523 - val_loss: 0.1429 - val_accuracy: 0.9688\n",
            "Epoch 154/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3993 - accuracy: 0.8562\n",
            "Epoch 154: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8552 - val_loss: 0.1488 - val_accuracy: 0.9663\n",
            "Epoch 155/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.4051 - accuracy: 0.8590\n",
            "Epoch 155: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8535 - val_loss: 0.1451 - val_accuracy: 0.9682\n",
            "Epoch 156/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.4084 - accuracy: 0.8504\n",
            "Epoch 156: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8515 - val_loss: 0.1509 - val_accuracy: 0.9663\n",
            "Epoch 157/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.4118 - accuracy: 0.8543\n",
            "Epoch 157: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4088 - accuracy: 0.8527 - val_loss: 0.1482 - val_accuracy: 0.9657\n",
            "Epoch 158/1000\n",
            "25/38 [==================>...........] - ETA: 0s - loss: 0.4088 - accuracy: 0.8512\n",
            "Epoch 158: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4085 - accuracy: 0.8525 - val_loss: 0.1463 - val_accuracy: 0.9676\n",
            "Epoch 159/1000\n",
            "24/38 [=================>............] - ETA: 0s - loss: 0.3909 - accuracy: 0.8581\n",
            "Epoch 159: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8540 - val_loss: 0.1409 - val_accuracy: 0.9713\n",
            "Epoch 160/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.4098 - accuracy: 0.8453\n",
            "Epoch 160: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8483 - val_loss: 0.1540 - val_accuracy: 0.9638\n",
            "Epoch 161/1000\n",
            "15/38 [==========>...................] - ETA: 0s - loss: 0.3858 - accuracy: 0.8661\n",
            "Epoch 161: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8521 - val_loss: 0.1435 - val_accuracy: 0.9682\n",
            "Epoch 162/1000\n",
            "27/38 [====================>.........] - ETA: 0s - loss: 0.4109 - accuracy: 0.8519\n",
            "Epoch 162: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4090 - accuracy: 0.8565 - val_loss: 0.1426 - val_accuracy: 0.9701\n",
            "Epoch 163/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.4149 - accuracy: 0.8418\n",
            "Epoch 163: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4055 - accuracy: 0.8475 - val_loss: 0.1465 - val_accuracy: 0.9669\n",
            "Epoch 164/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.4172 - accuracy: 0.8445\n",
            "Epoch 164: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8483 - val_loss: 0.1493 - val_accuracy: 0.9694\n",
            "Epoch 165/1000\n",
            "19/38 [==============>...............] - ETA: 0s - loss: 0.3679 - accuracy: 0.8565\n",
            "Epoch 165: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8623 - val_loss: 0.1431 - val_accuracy: 0.9694\n",
            "Epoch 166/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.3996 - accuracy: 0.8584\n",
            "Epoch 166: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8592 - val_loss: 0.1425 - val_accuracy: 0.9688\n",
            "Epoch 167/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.4021 - accuracy: 0.8537\n",
            "Epoch 167: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8550 - val_loss: 0.1433 - val_accuracy: 0.9701\n",
            "Epoch 168/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.3968 - accuracy: 0.8508\n",
            "Epoch 168: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8504 - val_loss: 0.1396 - val_accuracy: 0.9694\n",
            "Epoch 169/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.4039 - accuracy: 0.8587\n",
            "Epoch 169: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8598 - val_loss: 0.1356 - val_accuracy: 0.9719\n",
            "Epoch 170/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.4076 - accuracy: 0.8461\n",
            "Epoch 170: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8550 - val_loss: 0.1359 - val_accuracy: 0.9719\n",
            "Epoch 171/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3890 - accuracy: 0.8575\n",
            "Epoch 171: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8575 - val_loss: 0.1392 - val_accuracy: 0.9719\n",
            "Epoch 172/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.3943 - accuracy: 0.8645\n",
            "Epoch 172: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3928 - accuracy: 0.8629 - val_loss: 0.1401 - val_accuracy: 0.9701\n",
            "Epoch 173/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.4046 - accuracy: 0.8564\n",
            "Epoch 173: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8592 - val_loss: 0.1463 - val_accuracy: 0.9707\n",
            "Epoch 174/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.3881 - accuracy: 0.8584\n",
            "Epoch 174: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.8600 - val_loss: 0.1437 - val_accuracy: 0.9688\n",
            "Epoch 175/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.3890 - accuracy: 0.8594\n",
            "Epoch 175: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8558 - val_loss: 0.1481 - val_accuracy: 0.9682\n",
            "Epoch 176/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.3871 - accuracy: 0.8594\n",
            "Epoch 176: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3894 - accuracy: 0.8585 - val_loss: 0.1392 - val_accuracy: 0.9719\n",
            "Epoch 177/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4022 - accuracy: 0.8562\n",
            "Epoch 177: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4014 - accuracy: 0.8565 - val_loss: 0.1416 - val_accuracy: 0.9713\n",
            "Epoch 178/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3966 - accuracy: 0.8557\n",
            "Epoch 178: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8556 - val_loss: 0.1447 - val_accuracy: 0.9701\n",
            "Epoch 179/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3860 - accuracy: 0.8582\n",
            "Epoch 179: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.8592 - val_loss: 0.1366 - val_accuracy: 0.9713\n",
            "Epoch 180/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.4006 - accuracy: 0.8500\n",
            "Epoch 180: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8498 - val_loss: 0.1407 - val_accuracy: 0.9707\n",
            "Epoch 181/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.3945 - accuracy: 0.8535\n",
            "Epoch 181: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8569 - val_loss: 0.1457 - val_accuracy: 0.9688\n",
            "Epoch 182/1000\n",
            "26/38 [===================>..........] - ETA: 0s - loss: 0.3847 - accuracy: 0.8654\n",
            "Epoch 182: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8623 - val_loss: 0.1377 - val_accuracy: 0.9719\n",
            "Epoch 183/1000\n",
            "19/38 [==============>...............] - ETA: 0s - loss: 0.3739 - accuracy: 0.8557\n",
            "Epoch 183: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8473 - val_loss: 0.1366 - val_accuracy: 0.9726\n",
            "Epoch 184/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.3958 - accuracy: 0.8530\n",
            "Epoch 184: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8552 - val_loss: 0.1403 - val_accuracy: 0.9726\n",
            "Epoch 185/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.3701 - accuracy: 0.8649\n",
            "Epoch 185: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8615 - val_loss: 0.1402 - val_accuracy: 0.9719\n",
            "Epoch 186/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8640\n",
            "Epoch 186: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8635 - val_loss: 0.1471 - val_accuracy: 0.9694\n",
            "Epoch 187/1000\n",
            "23/38 [=================>............] - ETA: 0s - loss: 0.3769 - accuracy: 0.8563\n",
            "Epoch 187: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8552 - val_loss: 0.1435 - val_accuracy: 0.9719\n",
            "Epoch 188/1000\n",
            "24/38 [=================>............] - ETA: 0s - loss: 0.3916 - accuracy: 0.8620\n",
            "Epoch 188: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.8621 - val_loss: 0.1449 - val_accuracy: 0.9701\n",
            "Epoch 189/1000\n",
            "19/38 [==============>...............] - ETA: 0s - loss: 0.4165 - accuracy: 0.8532\n",
            "Epoch 189: saving model to /home/trinhnc/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8517 - val_loss: 0.1405 - val_accuracy: 0.9701\n",
            "Epoch 189: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f90996260d0>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=1000,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[cp_callback, es_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxvb2Y299hE3",
        "outputId": "59eb3185-2e37-4b9e-bc9d-ab1b8ac29b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9701\n"
          ]
        }
      ],
      "source": [
        "# Model evaluation\n",
        "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RBkmDeUW9hE4"
      },
      "outputs": [],
      "source": [
        "# Loading the saved model\n",
        "model = tf.keras.models.load_model(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFz9Tb0I9hE4",
        "outputId": "1c3b3528-54ae-4ee2-ab04-77429211cbef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 97ms/step\n",
            "[6.7029712e-03 1.4374901e-01 4.5037199e-10 2.2386561e-10 8.4954673e-01\n",
            " 1.3483615e-06]\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "# Inference test\n",
        "predict_result = model.predict(np.array([X_test[0]]))\n",
        "print(np.squeeze(predict_result))\n",
        "print(np.argmax(np.squeeze(predict_result)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3U4yNWx9hE4"
      },
      "source": [
        "# Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "AP1V6SCk9hE5",
        "outputId": "08e41a80-7a4a-4619-8125-ecc371368d19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       415\n",
            "           1       0.99      0.90      0.94       395\n",
            "           2       0.95      1.00      0.97       176\n",
            "           3       0.99      1.00      0.99       261\n",
            "           4       0.93      1.00      0.96       175\n",
            "           5       0.95      0.99      0.97       181\n",
            "\n",
            "    accuracy                           0.97      1603\n",
            "   macro avg       0.96      0.98      0.97      1603\n",
            "weighted avg       0.97      0.97      0.97      1603\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, report=True):\n",
        "    labels = sorted(list(set(y_true)))\n",
        "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    \n",
        "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
        " \n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
        "    ax.set_ylim(len(set(y_true)), 0)\n",
        "    plt.show()\n",
        "    \n",
        "    if report:\n",
        "        print('Classification Report')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNP6aqzc9hE5"
      },
      "source": [
        "# Convert to model for Tensorflow-Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ODjnYyld9hE6"
      },
      "outputs": [],
      "source": [
        "# Save as a model dedicated to inference\n",
        "model.save(model_save_path, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRfuK8Y59hE6",
        "outputId": "a4ca585c-b5d5-4244-8291-8674063209bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpk8m91t3_/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-31 00:20:20.189384: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
            "2022-12-31 00:20:20.189436: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
            "2022-12-31 00:20:20.190119: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpk8m91t3_\n",
            "2022-12-31 00:20:20.226265: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
            "2022-12-31 00:20:20.226322: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpk8m91t3_\n",
            "2022-12-31 00:20:20.306180: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
            "2022-12-31 00:20:20.313159: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
            "2022-12-31 00:20:20.488371: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpk8m91t3_\n",
            "2022-12-31 00:20:20.529855: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 339737 microseconds.\n",
            "2022-12-31 00:20:20.784109: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "6660"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transform model (quantization)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHBPBXdx9hE6"
      },
      "source": [
        "# Inference test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "mGAzLocO9hE7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        }
      ],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "oQuDK8YS9hE7"
      },
      "outputs": [],
      "source": [
        "# Get I / O tensor\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "2_ixAf_l9hE7"
      },
      "outputs": [],
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4FoAnuc9hE7",
        "outputId": "91f18257-8d8b-4ef3-c558-e9b5f94fabbf",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1.59 ms, sys: 128 s, total: 1.72 ms\n",
            "Wall time: 5.75 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Inference implementation\n",
        "interpreter.invoke()\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vONjp19J9hE8",
        "outputId": "77205e24-fd00-42c4-f7b6-e06e527c2cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6.7029702e-03 1.4374894e-01 4.5037366e-10 2.2386601e-10 8.4954673e-01\n",
            " 1.3483626e-06]\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "print(np.squeeze(tflite_results))\n",
        "print(np.argmax(np.squeeze(tflite_results)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "keypoint_classification_EN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
